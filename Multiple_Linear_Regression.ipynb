{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOoVwmW/+kxbLXr4tcyIEYM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaisshnavee1410/ASSIGNMENT-7-Multiple-Linear-Regression-.ipynb/blob/main/Multiple_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MULTIPLE LINEAR REGRESSION**"
      ],
      "metadata": {
        "id": "xdWhgNWrxDhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ASSIGNMENT TASKS:**"
      ],
      "metadata": {
        "id": "5-NmpiUKyC_e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your task is to perform a multiple linear regression analysis to predict the price of Toyota corolla\n",
        "based on the given attributes"
      ],
      "metadata": {
        "id": "gYVGSsjwx-C0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataset Description:**\n",
        "\n",
        "**The dataset consists of the following variables:**\n",
        "\n",
        "**Age:** Age in years\n",
        "\n",
        "**KM:** Accumulated Kilometers on odometer\n",
        "\n",
        "**FuelType:**  Fuel Type (Petrol, Diesel, CNG)\n",
        "\n",
        "**HP:** Horse Power\n",
        "\n",
        "**Automatic:** Automatic  (Yes=1, No=0)\n",
        "\n",
        "**CC:** Cylinder Volume in cubic centimeters\n",
        "\n",
        "**Doors:** Number of doors\n",
        "\n",
        "**Weight:** Weight in Kilograms\n",
        "\n",
        "**Quarterly_Tax:**\n",
        "\n",
        "**Price:** Offer Price in EUROs"
      ],
      "metadata": {
        "id": "qBb7nlRidvN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TASKS:**\n",
        "\n",
        "---> 1. Perform exploratory data analysis (EDA) to gain insights into the dataset. Provide visualizations\n",
        "and summary statistics of the variables. Pre process the data to apply the MLR."
      ],
      "metadata": {
        "id": "crb5U8VpeHqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **IMPORT NECESSARY LIBRARIES:**\n",
        "\n"
      ],
      "metadata": {
        "id": "WJAUpGN1gNDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Dataset\n",
        "df = pd.read_csv('ToyotaCorolla - MLR.csv')\n",
        "\n",
        "# Display dataset information and first few rows\n",
        "df.info()\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qmGLRBIMhAa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **SUMMARY STATISTICS:**\n",
        "\n"
      ],
      "metadata": {
        "id": "9SfqolHiiQIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics for numerical variables\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "0caZwaqYh02w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **DATA VISUALIZATIONS:**\n"
      ],
      "metadata": {
        "id": "d_1JmAgvivlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(A) HISTOGRAMS OF NUMERIC FEATURES:"
      ],
      "metadata": {
        "id": "WdIC4IVajP7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms for numerical columns\n",
        "fig, axes = plt.subplots(4, 3, figsize=(15, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, col in enumerate(df.select_dtypes(include=['int64']).columns):\n",
        "    sns.histplot(df[col], bins=30, kde=True, ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {col}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "A5LglvGaimwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(B)  SCATTER PLOTS:"
      ],
      "metadata": {
        "id": "e2HHpEhDkKLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plots\n",
        "fig, axes = plt.subplots(3, 2, figsize=(12, 12))\n",
        "\n",
        "sns.scatterplot(x=df[\"Age_08_04\"], y=df[\"Price\"], ax=axes[0, 0])\n",
        "axes[0, 0].set_title(\"Price vs Age\")\n",
        "\n",
        "sns.scatterplot(x=df[\"KM\"], y=df[\"Price\"], ax=axes[0, 1])\n",
        "axes[0, 1].set_title(\"Price vs KM\")\n",
        "\n",
        "sns.scatterplot(x=df[\"HP\"], y=df[\"Price\"], ax=axes[1, 0])\n",
        "axes[1, 0].set_title(\"Price vs Horse Power\")\n",
        "\n",
        "sns.scatterplot(x=df[\"cc\"], y=df[\"Price\"], ax=axes[1, 1])\n",
        "axes[1, 1].set_title(\"Price vs CC\")\n",
        "\n",
        "sns.scatterplot(x=df[\"Weight\"], y=df[\"Price\"], ax=axes[2, 0])\n",
        "axes[2, 0].set_title(\"Price vs Weight\")\n",
        "\n",
        "sns.boxplot(x=df[\"Fuel_Type\"], y=df[\"Price\"], ax=axes[2, 1])\n",
        "axes[2, 1].set_title(\"Price vs Fuel Type\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Op-G9NwwkG0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(C) CORRELATION HEATMAP:"
      ],
      "metadata": {
        "id": "uFUrOCYWms7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TRaJ3wsGmrPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **DATA PREPROCESSING OF MULTIPLE LINEAR REGRESSION:**"
      ],
      "metadata": {
        "id": "tt4NHBqpndX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(A)  Encode Categorical Variable (Fuel_Type):"
      ],
      "metadata": {
        "id": "C6CEaev8oD0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical column\n",
        "df = pd.get_dummies(df, columns=['Fuel_Type'], drop_first=True)"
      ],
      "metadata": {
        "id": "wzunZmYFnv1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " (B) Remove Unnecessary Columns:"
      ],
      "metadata": {
        "id": "OuBRpW2foo0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any non-essential columns\n",
        "df.drop(columns=['Cylinders'], inplace=True)"
      ],
      "metadata": {
        "id": "YjUY9cARndNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " (C) Check for Multicollinearity (Variance Inflation Factor - VIF):"
      ],
      "metadata": {
        "id": "Vq5r8I9PpOxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Define independent variables (excluding Price)\n",
        "X = df.drop(columns=['Price'])\n",
        "\n",
        "# Select only numeric columns for VIF calculation\n",
        "X_numeric = X.select_dtypes(include=['number'])\n",
        "\n",
        "# Calculate VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Feature\"] = X_numeric.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X_numeric.values, i) for i in range(X_numeric.shape[1])]\n",
        "\n",
        "print(vif_data)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PlOuWQMLpisk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> 2. Split the dataset into training and testing sets (e.g., 80% training, 20% testing)."
      ],
      "metadata": {
        "id": "e3bzq-deqDwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Import Required Libraries:**"
      ],
      "metadata": {
        "id": "K97ZBI-1sneU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "mkrBGjuosRhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Define Independent (X) and Dependent (y) Variables:**"
      ],
      "metadata": {
        "id": "YvgpMJEqstys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define independent variables (excluding Price)\n",
        "X = df.drop(columns=['Price'])\n",
        "\n",
        "# Define dependent variable (Price)\n",
        "y = df['Price']"
      ],
      "metadata": {
        "id": "aukTtJciptwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Split Data into Training (80%) and Testing (20%) Sets:**"
      ],
      "metadata": {
        "id": "8Id6kviyr4cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shape of the datasets\n",
        "print(\"Training Set Shape:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing Set Shape:\", X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "736MPOvKr0Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> 3. Build a multiple linear regression model using the training dataset. Interpret the coefficients of\n",
        "the model. Build minimum of 3 different models."
      ],
      "metadata": {
        "id": "EtE17PbJuZpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Import Required Libraries:**"
      ],
      "metadata": {
        "id": "glLL74NQu_NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('ToyotaCorolla - MLR.csv')\n",
        "\n",
        "# Convert categorical variable 'Fuel_Type' into dummy variables\n",
        "df = pd.get_dummies(df, columns=['Fuel_Type'], drop_first=True)\n",
        "\n",
        "# Define independent (X) and dependent (y) variables\n",
        "X = df.drop(columns=['Price'])  # Features\n",
        "y = df['Price']  # Target variable\n",
        "\n",
        "# Split data into training (80%) and testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "mbG6racbr-Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1:- Using All Features:"
      ],
      "metadata": {
        "id": "nek3BM1HvusV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Linear Regression Model\n",
        "model1 = LinearRegression()\n",
        "model1.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred1 = model1.predict(X_test)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"Model 1 - Using All Features\")\n",
        "print(\"R2 Score:\", r2_score(y_test, y_pred1))\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred1))\n",
        "\n",
        "# Display Model Coefficients\n",
        "coefficients1 = pd.DataFrame({'Feature': X.columns, 'Coefficient': model1.coef_})\n",
        "print(coefficients1)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xi53BDFBvoES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 2:- Using Only Significant Features (Age, KM, HP, Weight):"
      ],
      "metadata": {
        "id": "0N9tPKnPwMus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting specific features\n",
        "selected_features = ['Age_08_04', 'KM', 'HP', 'Weight']\n",
        "X_train2, X_test2 = X_train[selected_features], X_test[selected_features]\n",
        "\n",
        "# Train model\n",
        "model2 = LinearRegression()\n",
        "model2.fit(X_train2, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred2 = model2.predict(X_test2)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"\\nModel 2 - Using Selected Features (Age, KM, HP, Weight)\")\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred2))\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred2))\n",
        "\n",
        "# Display Model Coefficients\n",
        "coefficients2 = pd.DataFrame({'Feature': selected_features, 'Coefficient': model2.coef_})\n",
        "print(coefficients2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s5xradfpwHfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 3:- Using Only Engine and Transmission Features (CC, HP, Automatic, Weight):"
      ],
      "metadata": {
        "id": "CgPqfmEZwgaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting another set of features\n",
        "selected_features3 = ['cc', 'HP', 'Automatic', 'Weight']\n",
        "X_train3, X_test3 = X_train[selected_features3], X_test[selected_features3]\n",
        "\n",
        "# Train model\n",
        "model3 = LinearRegression()\n",
        "model3.fit(X_train3, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred3 = model3.predict(X_test3)\n",
        "\n",
        "# Model Evaluation\n",
        "print(\"\\nModel 3 - Engine and Transmission Features (CC, HP, Automatic, Weight)\")\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred3))\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred3))\n",
        "\n",
        "# Display Model Coefficients\n",
        "coefficients3 = pd.DataFrame({'Feature': selected_features3, 'Coefficient': model3.coef_})\n",
        "print(coefficients3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ILsPux9OxCwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3:-   Interpretation of Coefficients:"
      ],
      "metadata": {
        "id": "TtXLrS94wvhL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "   •\tPositive Coefficients (e.g., HP, Weight) indicate that an increase in these features leads to a higher price.\n",
        "\n",
        "   •\tNegative Coefficients (e.g., Age, KM) suggest that as these values increase, the car’s price decreases.\n",
        "\n",
        "   •\tAutomatic Transmission (Binary: 1 = Yes, 0 = No) will show a positive or negative impact on price."
      ],
      "metadata": {
        "id": "OaO49UaHw3O9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4:- Compare Model Performance:"
      ],
      "metadata": {
        "id": "I5nAd6ESw3LD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(f\"Model 1 (All Features) R2: {r2_score(y_test, y_pred1):.4f}\")\n",
        "print(f\"Model 2 (Age, KM, HP, Weight) R2: {r2_score(y_test, y_pred2):.4f}\")\n",
        "print(f\"Model 3 (CC, HP, Auto, Weight) R2: {r2_score(y_test, y_pred3):.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mPUmNpU1xOzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> 4. Evaluate the performance of the model using appropriate evaluation metrics on the testing\n",
        "dataset."
      ],
      "metadata": {
        "id": "HX_cw1FbyIRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics**\n",
        "\n",
        "1.\tR² Score – Measures how well the model explains the variance in the data.\n",
        "\n",
        "2.\tMean Squared Error (MSE) – Measures the average squared difference between actual and predicted values.\n",
        "\n",
        "3.\tMean Absolute Error (MAE) – Measures the absolute difference between actual and predicted values.\n",
        "\n",
        "4.\tRoot Mean Squared Error (RMSE) – Measures the standard deviation of residuals (errors)."
      ],
      "metadata": {
        "id": "eLB101KEyZjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to evaluate model performance\n",
        "def evaluate_model(model_name, y_test, y_pred):\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f\"\\nModel Performance: {model_name}\")\n",
        "    print(f\"R2 Score: {r2:.4f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "\n",
        "# Evaluate Model 1 (All Features)\n",
        "evaluate_model(\"Model 1 (All Features)\", y_test, y_pred1)\n",
        "\n",
        "# Evaluate Model 2 (Selected Features: Age, KM, HP, Weight)\n",
        "evaluate_model(\"Model 2 (Age, KM, HP, Weight)\", y_test, y_pred2)\n",
        "\n",
        "# Evaluate Model 3 (Engine & Transmission: CC, HP, Automatic, Weight)\n",
        "evaluate_model(\"Model 3 (CC, HP, Auto, Weight)\", y_test, y_pred3)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eYgUpWmTwVwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> 5. Apply Lasso and Ridge methods on the model"
      ],
      "metadata": {
        "id": "btgwJRg2zMvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Import Necessary Libraries:**"
      ],
      "metadata": {
        "id": "M3-CUtGjzn9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "# Standardize the dataset (important for Lasso & Ridge)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "-IMCqeROz8Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Apply Ridge Regression:**"
      ],
      "metadata": {
        "id": "Oflhl98B0AR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Ridge Regression Model with alpha=1 (Regularization Strength)\n",
        "ridge_model = Ridge(alpha=1.0)\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate Ridge Model\n",
        "evaluate_model(\"Ridge Regression\", y_test, y_pred_ridge)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NizwkaeVy11Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Apply Lasso Regression:**"
      ],
      "metadata": {
        "id": "z2Audv7m2O69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Lasso Regression Model with alpha=0.1 (Regularization Strength)\n",
        "lasso_model = Lasso(alpha=0.1)\n",
        "lasso_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lasso = lasso_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate Lasso Model\n",
        "evaluate_model(\"Lasso Regression\", y_test, y_pred_lasso)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KLqDReCrz31W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " * **Compare Ridge and Lasso Performance:**"
      ],
      "metadata": {
        "id": "mwFKgQVq2bMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nModel Performance Comparison:\")\n",
        "print(f\"Ridge Regression R2: {r2_score(y_test, y_pred_ridge):.4f}\")\n",
        "print(f\"Lasso Regression R2: {r2_score(y_test, y_pred_lasso):.4f}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Z7N9lphK2Uj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **INTERVIEW QUESTIONS:**"
      ],
      "metadata": {
        "id": "yT6_qAEY_Ehw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> **1.What is Normalization & Standardization and how is it helpful?**"
      ],
      "metadata": {
        "id": "ffwLju6Q_NbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization and Standardization are two key techniques in data preprocessing used to scale numerical data. They help improve the performance of machine learning algorithms by ensuring that features are on a similar scale."
      ],
      "metadata": {
        "id": "t7RYwEFy_ZEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **NORMALIZATION:**"
      ],
      "metadata": {
        "id": "sFifRjfD_joa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization is the process of scaling data to a fixed range, usually [0,1] or [-1,1]. It ensures that all features contribute equally to the model, preventing larger values from dominating smaller ones.\n"
      ],
      "metadata": {
        "id": "PdX5K6Lx_hui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When to Use?**\n",
        "\n",
        "•\tWhen data is not normally distributed (not Gaussian).\n",
        "\n",
        "•\tWhen working with neural networks and distance-based algorithms (like KNN).\n",
        "\n",
        "•\tUseful in cases where we need to compare different feature scale"
      ],
      "metadata": {
        "id": "T-xM_pcx_2Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **STANDARDIZATION:**"
      ],
      "metadata": {
        "id": "gx1_tiEmALCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization transforms data so that it has a mean of 0 and a standard deviation of 1. This ensures that the data follows a standard normal distribution."
      ],
      "metadata": {
        "id": "RiaYtKHJAK-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When to Use?**\n",
        "\n",
        "•\tWhen data follows a normal (Gaussian) distribution.\n",
        "\n",
        "•\tWhen using models like Linear Regression, Logistic Regression, Support Vector Machines (SVM), and PCA.\n",
        "\n",
        "•\tWhen handling features with different units of measurement (e.g., height in cm and weight in kg).\n"
      ],
      "metadata": {
        "id": "ZTXCC_EFA1ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why is Normalization and Standardization Helpful?**\n",
        "\n",
        "* **Improves Model Performance:** Prevents large values from dominating the learning process.\n",
        "\n",
        "* **Speeds Up Training:** Optimizers like gradient descent work faster when features are on the same scale.\n",
        "\n",
        "* **Enhances Accuracy:** Ensures all features contribute equally to decision-making.\n",
        "\n",
        "* **Reduces Computational Complexity:** Models converge faster when features are scaled properly.\n"
      ],
      "metadata": {
        "id": "yfzg3FY_BI0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--> **2. What techniques can be used to address multicollinearity in multiple linear regression?**"
      ],
      "metadata": {
        "id": "NBwRrf8aCATp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicollinearity occurs when two or more independent variables in a regression model are highly correlated, making it difficult to determine the individual effect of each predictor. This can lead to unreliable coefficient estimates and high variance in predictions.\n"
      ],
      "metadata": {
        "id": "pxuLLewWCAQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Remove Highly Correlated Predictors:**\n",
        "\n",
        "\n",
        "•\tUse the correlation matrix or Variance Inflation Factor (VIF) to identify highly correlated variables.\n",
        "\n",
        "  •\tRemove one of the correlated variables if it provides redundant information.\n"
      ],
      "metadata": {
        "id": "mGru7KDmCZ9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Principal Component Analysis (PCA):**\n",
        "\n",
        "•\tPCA reduces dimensionality by transforming correlated features into uncorrelated principal components.\n",
        "\n",
        "•\tInstead of using original variables, use the principal components as predictors in the model.\n"
      ],
      "metadata": {
        "id": "NpPtweQoCj6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Ridge Regression (L2 Regularization):**\n",
        "\n",
        "•\tRidge regression penalizes large coefficients, which reduces the impact of multicollinearity.\n",
        "\n",
        "•\tUnlike standard regression, it does not eliminate variables but shrinks their coefficients."
      ],
      "metadata": {
        "id": "hf6q1whDCj3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Lasso Regression (L1 Regularization):**\n",
        "\n",
        "•\tLasso regression eliminates some coefficients by setting them to zero, effectively performing variable selection.\n",
        "\n",
        "•\tHelps remove highly correlated variables automatically.\n"
      ],
      "metadata": {
        "id": "x6LexSVZCj05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Combine or Create New Features:**\n",
        "\n",
        "•\tIf two variables are highly correlated, consider combining them into a single feature (e.g., sum, average, or ratio).\n",
        "\n",
        "•\tExample: Instead of using Height and Weight separately, use BMI (Weight/Height²)"
      ],
      "metadata": {
        "id": "42Un6tNgDlTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **Increase Sample Size:**\n",
        "\n",
        "•\tIf possible, collect more data. Larger datasets can reduce the impact of multicollinearity."
      ],
      "metadata": {
        "id": "kupXkp3oDlQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Use Domain Knowledge:**\n",
        "\n",
        "•\tSelect variables based on business logic rather than just statistical correlation.\n",
        "\n",
        "•\tIf two variables measure the same concept, keep the one that is more interpretable."
      ],
      "metadata": {
        "id": "ES1SizhQDlNb"
      }
    }
  ]
}